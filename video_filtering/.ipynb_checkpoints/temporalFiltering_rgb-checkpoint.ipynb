{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, cv2\n",
    "import torchvision\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "from math import log10, pi\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import utils\n",
    "from copy import deepcopy\n",
    "from skimage.transform import rescale\n",
    "# for flow\n",
    "import models\n",
    "\n",
    "# for temporal\n",
    "import pickle\n",
    "import networks\n",
    "\n",
    "class TransformerNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerNet, self).__init__()\n",
    "        # Initial convolution layers\n",
    "        self.conv1 = ConvLayer(4, 32, kernel_size=9, stride=1)\n",
    "        self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n",
    "        self.conv2 = ConvLayer(32, 64, kernel_size=3, stride=2)\n",
    "        self.in2 = torch.nn.InstanceNorm2d(64, affine=True)\n",
    "        self.conv3 = ConvLayer(64, 128, kernel_size=3, stride=2)\n",
    "        self.in3 = torch.nn.InstanceNorm2d(128, affine=True)\n",
    "        # Residual layers\n",
    "        self.res1 = ResidualBlock(128)\n",
    "        self.res2 = ResidualBlock(128)\n",
    "        self.res3 = ResidualBlock(128)\n",
    "        self.res4 = ResidualBlock(128)\n",
    "        self.res5 = ResidualBlock(128)\n",
    "        self.res6 = ResidualBlock(128)\n",
    "        self.res7 = ResidualBlock(128)\n",
    "        self.res8 = ResidualBlock(128)\n",
    "        self.res9 = ResidualBlock(128)\n",
    "        self.res10 = ResidualBlock(128)\n",
    "        self.res11 = ResidualBlock(128)\n",
    "        self.res12 = ResidualBlock(128)\n",
    "        self.res13 = ResidualBlock(128)\n",
    "        self.res14 = ResidualBlock(128)\n",
    "        self.res15 = ResidualBlock(128)\n",
    "        self.res16 = ResidualBlock(128)\n",
    "\n",
    "        # Upsampling Layers\n",
    "        self.deconv1 = UpsampleConvLayer(128*2, 64, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in4 = torch.nn.InstanceNorm2d(64, affine=True)\n",
    "        self.deconv2 = UpsampleConvLayer(64*2, 32, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in5 = torch.nn.InstanceNorm2d(32, affine=True)\n",
    "        self.deconv3 = ConvLayer(32*2, 3, kernel_size=9, stride=1)\n",
    "        # Non-linearities\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        o1 = self.relu(self.conv1(X))\n",
    "        o2 = self.relu(self.conv2(o1))\n",
    "        o3 = self.relu(self.conv3(o2))\n",
    "\n",
    "        y = self.res1(o3)\n",
    "        y = self.res2(y)\n",
    "        y = self.res3(y)\n",
    "        y = self.res4(y)\n",
    "        y = self.res5(y)\n",
    "        y = self.res6(y)\n",
    "        y = self.res7(y)\n",
    "        y = self.res8(y)\n",
    "        y = self.res9(y)\n",
    "        y = self.res10(y)\n",
    "        y = self.res11(y)\n",
    "        y = self.res12(y)\n",
    "        y = self.res13(y)\n",
    "        y = self.res14(y)\n",
    "        y = self.res15(y)\n",
    "        y = self.res16(y)\n",
    "        \n",
    "        in1 = torch.cat( (y, o3), 1 )\n",
    "        y = self.relu(self.deconv1(in1))\n",
    "        in2 = torch.cat( (y, o2), 1 )\n",
    "        y = self.relu(self.deconv2(in2))\n",
    "        in3 = torch.cat( (y, o1), 1 )\n",
    "        y = self.deconv3(in3)\n",
    "        \n",
    "        return y\n",
    "\n",
    "class ConvLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.reflection_pad(x)\n",
    "        out = self.conv2d(out)\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(torch.nn.Module):  \n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out = out + residual\n",
    "        return out\n",
    "\n",
    "class UpsampleConvLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super(UpsampleConvLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = torch.nn.functional.interpolate(x_in, mode='nearest', scale_factor=self.upsample)\n",
    "        out = self.reflection_pad(x_in)\n",
    "        out = self.conv2d(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformNet(\n",
       "  (conv1a): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (conv2d): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (norm_layer): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (conv1b): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (conv2d): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (norm_layer): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (conv2a): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (norm_layer): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (conv2b): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (norm_layer): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (ResBlocks): ModuleList(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (norm_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (convlstm): ConvLSTM(\n",
       "    (Gates): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (deconv1): UpsampleConvLayer(\n",
       "    (upsample_layer): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (norm_layer): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (deconv2): UpsampleConvLayer(\n",
       "    (upsample_layer): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (norm_layer): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (deconv3): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (conv2d): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "  )\n",
       "  (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "######################################################################################\n",
    "# Load flow computation network    \n",
    "pwc_model_fn = './pwc_net.pth.tar'\n",
    "\n",
    "PWCNet = models.pwc_dc_net(pwc_model_fn)\n",
    "PWCNet = PWCNet.float().to(device)\n",
    "PWCNet.eval() \n",
    "######################################################################################\n",
    "### load consistency nework\n",
    "\n",
    "filename = 'fast_blind_video_consistency'\n",
    "opts_filename = os.path.join(filename, 'pretrained_models', \"ECCV18_blind_consistency_opts.pth\")\n",
    "with open(opts_filename, 'rb') as f:\n",
    "    temporal_model_opts = pickle.load(f)\n",
    "\n",
    "temporal_model = networks.__dict__[temporal_model_opts.model](temporal_model_opts, nc_in=12, nc_out=3)\n",
    "\n",
    "model_filename = os.path.join(filename, 'pretrained_models', \"ECCV18_blind_consistency.pth\")\n",
    "state_dict = torch.load(model_filename)\n",
    "temporal_model.load_state_dict(state_dict['model'])\n",
    "\n",
    "temporal_model = temporal_model.to(device)\n",
    "temporal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerNet(\n",
       "  (conv1): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((4, 4, 4, 4))\n",
       "    (conv2d): Conv2d(4, 32, kernel_size=(9, 9), stride=(1, 1))\n",
       "  )\n",
       "  (in1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  (conv2): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (in2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  (conv3): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (in3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  (res1): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res2): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res3): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res4): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res5): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res6): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res7): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res8): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res9): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res10): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res11): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res12): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res13): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res14): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res15): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res16): ResidualBlock(\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (deconv1): UpsampleConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (in4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  (deconv2): UpsampleConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2d): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (in5): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  (deconv3): ConvLayer(\n",
       "    (reflection_pad): ReflectionPad2d((4, 4, 4, 4))\n",
       "    (conv2d): Conv2d(64, 3, kernel_size=(9, 9), stride=(1, 1))\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image filtering network\n",
    "FilterModel = TransformerNet()\n",
    "criterion = nn.MSELoss()\n",
    " \n",
    "FilterModel.load_state_dict( torch.load('trained_model/10-23vggl1-1-Unet_gaussian04_256_randomRGB_Mod.ckpt') )\n",
    "# FilterModel.load_state_dict( torch.load('trained_model/10-31_vggl2-001_res_U_net.ckpt') )\n",
    "# FilterModel.load_state_dict( torch.load('trained_model/10-14vggl2-001-Unet_2800_randomRGB.ckpt') )\n",
    "\n",
    "FilterModel = FilterModel.float().to(device)\n",
    "FilterModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_frame = 1           ########### need explicitly assigned first frame:0 second: 1\n",
    "bright = 20             ########### need explicitly assigned    \n",
    "gamma = 0.4\n",
    "gamma_out = 0.8\n",
    "directory = '1111_2'\n",
    "white = 'noWhite'\n",
    "version = '1023'\n",
    "\n",
    "data_root = os.path.join('out_2020/', directory)\n",
    "\n",
    "if not os.path.exists(data_root):\n",
    "    os.makedirs(data_root)\n",
    "\n",
    "# noise_var = 0.1\n",
    "######################################################################################\n",
    "# read avi video generate synthetic data (no compression)\n",
    "video = cv2.VideoCapture('out/%s/test_%s.avi' % (directory, white) )\n",
    "# video = cv2.VideoCapture('out/%s/test.avi' % (directory) )\n",
    "i=0\n",
    "inputs_all = []\n",
    "out_all = []\n",
    "while(video.isOpened()):\n",
    "    ret, frame = video.read()\n",
    "    if i < red_frame:\n",
    "        i = i+1\n",
    "        continue\n",
    "    if ret == True:\n",
    "        im = cv2.cvtColor( frame, cv2.COLOR_BGR2RGB )\n",
    "        \n",
    "#         img = im[::2, ::2, :] # human_4\n",
    "#         im = img\n",
    "    \n",
    "        im = im / 255\n",
    "        if np.mod(i-red_frame+1,2) == 0:\n",
    "            im = (im*bright)**gamma\n",
    "        if i >= red_frame:\n",
    "            inputs_all.append(im)\n",
    "        i = i+1\n",
    "    else:\n",
    "        break  \n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
      "/tmp/pip-req-build-4baxydiv/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n"
     ]
    }
   ],
   "source": [
    "######################## interpolate guide by flow ###################################\n",
    "length = len(inputs_all)\n",
    "row, col, ch = inputs_all[0].shape\n",
    "num = 4                     ###### need explicitly assigned\n",
    "times_flow = []\n",
    "times_warp = []\n",
    "times_filter = []\n",
    "\n",
    "h1 = int(row/64) * 64\n",
    "w1 = int(col/64) * 64\n",
    "\n",
    "inputs = np.zeros([ h1, w1, ch+1, num*2 ])\n",
    "guide = np.zeros([ h1, w1, ch*2, num ])\n",
    "guide_flow = np.zeros([ h1, w1, ch*2, num ])\n",
    "outFrame = []\n",
    "FilterOutputs = []\n",
    "\n",
    "##################### gaussian noise, can be tuned ###################\n",
    "# gauss = utils.generateGaussNoise(inputs[:,:,0:3,0], 0, noise_var)\n",
    "# gauss[:,:,0] = gauss[:,:,0] / 2\n",
    "# gauss_cuda = torch.unsqueeze(torch.from_numpy( np.transpose(gauss,(2,0,1)) ),0 ).float().to(device)\n",
    "\n",
    "for i in range( int( (length-2)/num/2 ) ):\n",
    "    ind = i*2*num\n",
    "    for j in range(num):\n",
    "        g_1 = inputs_all[ind+2*j+2][0:h1, 0:w1, 0:1] + inputs_all[ind+2*j+2][0:h1, 0:w1, 1:2]+inputs_all[ind+2*j+2][0:h1, 0:w1, 2:3]\n",
    "        g_2 = inputs_all[ind+2*j][0:h1, 0:w1, 0:1] + inputs_all[ind+2*j][0:h1, 0:w1, 1:2] + inputs_all[ind+2*j][0:h1, 0:w1, 2:3]\n",
    "#         print(np.max(g_1), np.max(g_2))\n",
    "#         g_1 = g_1 / np.max(g_1)\n",
    "#         g_2 = g_2 / np.max(g_2)\n",
    "    \n",
    "        guide[:,:,:,j] = np.concatenate( ( np.tile( g_1, (1,1,3) ), np.tile( g_2, (1,1,3) ) ), 2)\n",
    "        g_1 = inputs_all[ind+2*j+2][0:h1, 0:w1, 0:1]\n",
    "        g_2 = inputs_all[ind+2*j][0:h1, 0:w1, 0:1]\n",
    "        guide_flow[:,:,:,j] = np.concatenate( ( np.tile( g_1, (1,1,3) ), np.tile( g_2, (1,1,3) ) ), 2)\n",
    "        \n",
    "        inputs[:,:,0:3,j*2] = inputs_all[ind+2*j+1][0:h1, 0:w1, 0:3]\n",
    "        inputs[:,:,3:4,j*2+1] = inputs_all[ind+2*j+2][0:h1, 0:w1, 0:1]\n",
    "        \n",
    "        out_all.append(inputs_all[ind+2*j+1][0:h1, 0:w1, 0:3])\n",
    "\n",
    "    guide_cuda = torch.from_numpy( np.transpose( guide, (3,2,0,1)) ).float().to(device)\n",
    "    inputs_cuda = torch.from_numpy( np.transpose( inputs, (3,2,0,1)) ).float().to(device)\n",
    "    guideFlow_cuda = torch.from_numpy( np.transpose( guide_flow, (3,2,0,1)) ).float().to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        flo_all = PWCNet(guideFlow_cuda)\n",
    "    flo_all = flo_all * 20.0\n",
    "    flo_all = torch.nn.functional.interpolate(flo_all, mode='bilinear', scale_factor=4, align_corners=True)\n",
    "    times_flow.append( time.time() - start_time )\n",
    "\n",
    "    start_time = time.time()\n",
    "    for j in range(num):\n",
    "        max_guide = torch.max(guide_cuda[j:j+1,3:4,:,:])\n",
    "        inputs_cuda[2*j:2*j+1,3:4,:,:] = utils.warp( guide_cuda[j:j+1,3:4,:,:] / max_guide, flo_all[j:j+1,:,:,:]/2 )\n",
    "        inputs_cuda[2*j:2*j+1,3:4,:,:] = inputs_cuda[2*j:2*j+1,3:4,:,:] * max_guide\n",
    "        inputs_cuda[2*j+1:2*j+2,0:3,:,:] = utils.warp( inputs_cuda[2*j:2*j+1,0:3,:,:], flo_all[j:j+1,:,:,:]/2 )\n",
    "    \n",
    "    times_warp.append( time.time() - start_time )\n",
    "    \n",
    "    for j in range(2):\n",
    "        with torch.no_grad(): \n",
    "            \n",
    "            start_time = time.time()\n",
    "            outputs = FilterModel(inputs_cuda[j*num:(j+1)*num,:,:,:])\n",
    "            times_filter.append( time.time() - start_time )\n",
    "            \n",
    "            for k in range( outputs.size()[0] ):\n",
    "                FilterOutputs.append( outputs[k:k+1,:,:,:] )\n",
    "                \n",
    "            outFrame.append( np.transpose(outputs.cpu().numpy(),(2,3,1,0) ) )\n",
    "\n",
    "Frame = out_all\n",
    "img_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Write video ####################################\n",
    "Frame = []\n",
    "img_array = []\n",
    "\n",
    "for i in range( len(outFrame) ):\n",
    "    for j in range( outFrame[i].shape[3] ):\n",
    "        Frame.append( outFrame[i][:,:,:,j] )\n",
    "\n",
    "for idx in range(len(Frame)):    \n",
    "    img = Frame[idx]\n",
    "    img = img[10:768-10, 300:1024-10, :]\n",
    "    img = utils.validate_im( img )\n",
    "    img = utils.imageWhite(img, 1, 1.1, 1.9)**0.6\n",
    "    img = utils.validate_im( img )\n",
    "    \n",
    "    img = (img*255).astype('uint8')\n",
    "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB ) # change the color space when read and write\n",
    "    \n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('%s/out_single_%s-%s_%s_%s.mov' % (data_root, bright, gamma, version, white), fourcc, 20, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Temporal consistency ########################\n",
    "\n",
    "frame_o2 = FilterOutputs[0]\n",
    "lstm_state = None\n",
    "\n",
    "times_temporal = []\n",
    "outFrame = []\n",
    "outFrame.append( np.transpose(frame_o2.cpu().numpy().squeeze(0),(1,2,0) ) )\n",
    "\n",
    "for t in range(1, len(FilterOutputs)):\n",
    "    frame_i1 = FilterOutputs[t-1]\n",
    "    frame_i2 = FilterOutputs[t]\n",
    "    frame_o1 = frame_o2\n",
    "    frame_p2 = frame_i2\n",
    "      \n",
    "    with torch.no_grad(): \n",
    "        inputs_cuda = torch.cat((frame_p2, frame_o1, frame_i2, frame_i1), dim=1)        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        outputs, lstm_state = temporal_model(inputs_cuda, lstm_state)        \n",
    "        \n",
    "        frame_o2 = frame_p2 + outputs\n",
    "        times_temporal.append( time.time() - start_time )\n",
    "        \n",
    "        ## create new variable to detach from graph and avoid memory accumulation\n",
    "        lstm_state = utils.repackage_hidden(lstm_state)        \n",
    "    outFrame.append( np.transpose(frame_o2.cpu().numpy().squeeze(0),(1,2,0) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame total number: 46 \n",
      "\n",
      "Frame total number: 23 \n",
      "Flow time: 0.4147 seconds \n",
      "Warp time: 1.1373 seconds \n",
      "Filter time: 0.0534 seconds \n",
      "Temporal time: 0.1415 seconds\n"
     ]
    }
   ],
   "source": [
    "#################### Write video ########################################\n",
    "Frame = deepcopy(outFrame)\n",
    "img_array = []\n",
    "\n",
    "for idx in range(len(Frame)-10):    \n",
    "    img = Frame[idx]\n",
    "    img = img[10:768-10, 300:1024-10, :]\n",
    "    img = utils.validate_im( img )\n",
    "    img = utils.imageWhite(img, 1, 1.1, 1.9)**0.6\n",
    "    img = utils.validate_im( img )\n",
    "    \n",
    "    img = (img*255).astype('uint8')\n",
    "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB ) # change the color space when read and write\n",
    "    \n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "#     if np.mod(idx,2) == 0: ##### for rgb only, frame rate / 2 \n",
    "#         img_array.append(img)\n",
    "    img_array.append(img)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('%s/out_temporal_%s-%s_%s_%s.mov' % (data_root, bright, gamma, version, white), fourcc, 20, size)\n",
    "# out = cv2.VideoWriter('%s/out_temporal_%s.mov' % (data_root, version), fourcc, 20/2, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n",
    "print( \"Frame total number: %2d \\n\" %(len(img_array)) )\n",
    "\n",
    "#################### Write input video ########################################\n",
    "Frame = deepcopy(out_all)\n",
    "img_array = []\n",
    "\n",
    "for idx in range(len(Frame)-5):    \n",
    "    img = Frame[idx]\n",
    "    img = img[10:768-10, 300:1024-10, :]\n",
    "    img = utils.validate_im( img )\n",
    "    img = utils.imageWhite(img, 1, 1, 1.3)**0.8\n",
    "    img = utils.validate_im( img + gauss )\n",
    "    \n",
    "#     gauss = utils.generateGaussNoise(img, 0, 0.2)*utils.generateGaussNoise(img, 0, 0.2)\n",
    "#     img = utils.validate_im( img + gauss )\n",
    "#     gauss = utils.generateGaussNoise(img, 0, 0.03)\n",
    "#     img = utils.validate_im( img + gauss )\n",
    "    \n",
    "    img = (img*255).astype('uint8')\n",
    "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB ) # change the color space when read and write\n",
    "    \n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('%s/input_%s-%s_%s.mov' % (data_root, bright, gamma, white), fourcc, 20/2, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n",
    "\n",
    "\n",
    "print( \"Frame total number: %2d \\nFlow time: %0.4f seconds \\nWarp time: %0.4f seconds \\nFilter time: %0.4f seconds \\nTemporal time: %0.4f seconds\" %(len(img_array), sum(times_flow), sum(times_warp), sum(times_filter), sum(times_temporal) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Write temporal frame ########################################\n",
    "Frame = deepcopy(outFrame)\n",
    "img_array = []\n",
    "\n",
    "for idx in [1,4,27]:\n",
    "    img = Frame[idx]\n",
    "    img = utils.validate_im( img )\n",
    "#     img = img**gamma_out\n",
    "    img = (img*255).astype('uint8')\n",
    "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB )\n",
    "    \n",
    "    cv2.imwrite( '%s/out_%s.png' %(data_root, str(idx)), img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Write input frame ########################################\n",
    "Frame = deepcopy(inputs_all)\n",
    "img_array = []\n",
    "\n",
    "for idx in [1, 4, 7]:\n",
    "    img = Frame[idx]\n",
    "    img = utils.validate_im( img )\n",
    "    \n",
    "    img = (img*255).astype('uint8')\n",
    "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB )\n",
    "    \n",
    "    cv2.imwrite( '%s/input_%s.png' %(data_root, str(idx)), img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
